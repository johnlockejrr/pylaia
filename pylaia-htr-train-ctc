#!/usr/bin/env python3
import argparse
import multiprocessing
import os
import random

import numpy
import torch
from torch.optim import SGD, Adam, AdamW, RMSprop

import laia.common.logging as log
import laia.data.transforms as transforms
from laia import __version__
from laia.common.arguments import add_argument, add_defaults, args
from laia.common.arguments_types import NumberInClosedRange
from laia.common.loader import ModelLoader, StateCheckpointLoader
from laia.common.random import manual_seed
from laia.common.saver import (
    CheckpointSaver,
    ModelCheckpointSaver,
    RollingSaver,
    StateCheckpointSaver,
)
from laia.conditions import ConsecutiveNonDecreasing, GEqThan, Lowest, MultipleOf
from laia.data import FixedSizeSampler, ImageDataLoader, TextImageFromTextTableDataset
from laia.engine import Evaluator, Trainer
from laia.engine.engine import EPOCH_END, EPOCH_START
from laia.engine.feeders import ImageFeeder, ItemFeeder
from laia.experiments.htr_experiment import HTRExperiment
from laia.hooks import Action, Hook, HookList, action
from laia.utils import SymbolsTable


def worker_init_fn(_):
    # We need to reset the Numpy and Python PRNG, or we will get the
    # same numbers in each epoch (when the workers are re-generated)
    random.seed(torch.initial_seed() % 2 ** 31)
    numpy.random.seed(torch.initial_seed() % 2 ** 31)


if __name__ == "__main__":
    add_defaults(
        "batch_size",
        "learning_rate",
        "momentum",
        "weight_l2_penalty",
        "nesterov",
        "gpu",
        "max_epochs",
        "seed",
        "show_progress_bar",
        "train_path",
        "train_samples_per_epoch",
        "valid_samples_per_epoch",
        "iterations_per_update",
        "color_mode",
        "save_checkpoint_interval",
        "num_rolling_checkpoints",
        "use_distortions",
        "print_args",
    )
    add_argument(
        "syms",
        type=argparse.FileType("r"),
        help="Symbols table mapping from strings to integers.",
    )
    add_argument(
        "img_dirs", type=str, nargs="+", help="Directory containing word images."
    )
    add_argument(
        "tr_txt_table",
        type=argparse.FileType("r"),
        help="Character transcriptions of each training image.",
    )
    add_argument(
        "va_txt_table",
        type=argparse.FileType("r"),
        help="Character transcriptions of each validation image.",
    )
    add_argument(
        "--delimiters",
        type=str,
        nargs="+",
        default=["<space>"],
        help="Sequence of characters representing the word delimiters.",
    )
    add_argument(
        "--max_nondecreasing_epochs",
        type=NumberInClosedRange(int, vmin=0),
        help="Stop the training once there has been this number "
        "consecutive epochs without a new lowest validation CER.",
    )
    add_argument(
        "--model_filename", type=str, default="model", help="File name of the model."
    )
    add_argument(
        "--checkpoint",
        type=str,
        default="ckpt.lowest-valid-cer*",
        help="Suffix of the checkpoint to use, can be a glob pattern.",
    )
    add_argument(
        "--optimizer",
        type=str,
        default="RMSProp",
        choices=["SGD", "RMSProp", "Adam", "AdamW"],
        help="Optimization algorithm.",
    )
    # Deprecated arguments:
    add_argument(
        "--use_baidu_ctc",
        "--add_logsoftmax_to_loss",
        action="store_true",
        help=argparse.SUPPRESS,
    )
    args = args()

    log.info("PyLaia version: {}".format(__version__))

    manual_seed(args.seed)
    syms = SymbolsTable(args.syms)
    device = torch.device("cuda:{}".format(args.gpu - 1) if args.gpu else "cpu")

    model = ModelLoader(
        args.train_path, filename=args.model_filename, device=device
    ).load()
    if model is None:
        log.error('Could not find the model. Have you run "pylaia-htr-create-model"?')
        exit(1)
    model = model.to(device)

    default_img_transform = transforms.vision.ToImageTensor(
        mode=args.color_mode, invert=True
    )
    if args.use_distortions:
        tr_img_transform = transforms.Compose(
            [
                transforms.vision.Convert(args.color_mode),
                transforms.vision.Invert(),
                transforms.vision.RandomBetaAffine(),
                transforms.vision.ToTensor(),
            ]
        )
    else:
        tr_img_transform = default_img_transform
    log.info("Training data transforms:\n{}", str(tr_img_transform))

    tr_dataset = TextImageFromTextTableDataset(
        args.tr_txt_table,
        args.img_dirs,
        img_transform=tr_img_transform,
        txt_transform=transforms.text.ToTensor(syms),
    )
    tr_dataset_loader = ImageDataLoader(
        dataset=tr_dataset,
        image_channels=len(args.color_mode),
        batch_size=args.batch_size,
        num_workers=multiprocessing.cpu_count(),
        shuffle=not bool(args.train_samples_per_epoch),
        sampler=FixedSizeSampler(tr_dataset, args.train_samples_per_epoch)
        if args.train_samples_per_epoch
        else None,
        worker_init_fn=worker_init_fn,
    )

    if args.optimizer == "SGD":
        optimizer = SGD(
            model.parameters(),
            lr=args.learning_rate,
            momentum=args.momentum,
            weight_decay=args.weight_l2_penalty,
            nesterov=args.nesterov,
        )
    elif args.optimizer == "RMSProp":
        optimizer = RMSprop(
            model.parameters(),
            lr=args.learning_rate,
            weight_decay=args.weight_l2_penalty,
            momentum=args.momentum,
        )
    elif args.optimizer == "Adam":
        optimizer = Adam(
            model.parameters(),
            lr=args.learning_rate,
            weight_decay=args.weight_l2_penalty,
        )
    elif args.optimizer == "AdamW":
        if args.weight_l2_penalty == 0.0:
            log.warning("Using 0.0 weight decay with AdamW")
        optimizer = AdamW(
            model.parameters(),
            lr=args.learning_rate,
            weight_decay=args.weight_l2_penalty,
        )

    trainer = Trainer(
        model=model,
        criterion=None,  # Set automatically by HTRExperiment
        optimizer=optimizer,
        data_loader=tr_dataset_loader,
        batch_input_fn=ImageFeeder(device=device, parent_feeder=ItemFeeder("img")),
        batch_target_fn=ItemFeeder("txt"),
        batch_id_fn=ItemFeeder("id"),  # Print image ids on exception
        progress_bar="Train" if args.show_progress_bar else None,
        iterations_per_update=args.iterations_per_update,
    )

    va_dataset = TextImageFromTextTableDataset(
        args.va_txt_table,
        args.img_dirs,
        img_transform=default_img_transform,
        txt_transform=transforms.text.ToTensor(syms),
    )
    va_dataset_loader = ImageDataLoader(
        dataset=va_dataset,
        image_channels=len(args.color_mode),
        batch_size=args.batch_size,
        num_workers=multiprocessing.cpu_count(),
        sampler=FixedSizeSampler(va_dataset, args.valid_samples_per_epoch)
        if args.valid_samples_per_epoch
        else None,
    )
    evaluator = Evaluator(
        model=model,
        data_loader=va_dataset_loader,
        batch_input_fn=ImageFeeder(device=device, parent_feeder=ItemFeeder("img")),
        batch_target_fn=ItemFeeder("txt"),
        batch_id_fn=ItemFeeder("id"),
        progress_bar="Valid" if args.show_progress_bar else None,
    )

    experiment = HTRExperiment(
        trainer, evaluator, word_delimiters=[syms[sym] for sym in args.delimiters]
    )

    def ckpt_saver(filename, obj):
        return RollingSaver(
            StateCheckpointSaver(
                CheckpointSaver(os.path.join(args.train_path, filename)),
                obj,
                device=device,
            ),
            keep=args.num_rolling_checkpoints,
        )

    saver_best_cer = ckpt_saver("experiment.ckpt.lowest-valid-cer", experiment)
    saver_best_wer = ckpt_saver("experiment.ckpt.lowest-valid-wer", experiment)

    @action
    def save(saver, epoch):
        saver.save(suffix=epoch)

    # Set hooks
    trainer.add_hook(
        EPOCH_END,
        HookList(
            # Save on best CER
            Hook(Lowest(experiment.valid_cer()), Action(save, saver=saver_best_cer)),
            # Save on best WER
            Hook(Lowest(experiment.valid_wer()), Action(save, saver=saver_best_wer)),
        ),
    )
    if args.save_checkpoint_interval:
        # Save every `save_checkpoint_interval` epochs
        log.get_logger("laia.hooks.conditions.multiple_of").setLevel(log.WARNING)
        trainer.add_hook(
            EPOCH_END,
            Hook(
                MultipleOf(trainer.epochs, args.save_checkpoint_interval),
                Action(save, saver=ckpt_saver("experiment.ckpt", experiment)),
            ),
        )
    if args.max_nondecreasing_epochs:
        # Stop when the validation CER hasn't improved in
        # `max_nondecreasing_epochs` consecutive epochs
        trainer.add_hook(
            EPOCH_END,
            Hook(
                ConsecutiveNonDecreasing(
                    experiment.valid_cer(), args.max_nondecreasing_epochs
                ),
                trainer.stop,
            ),
        )
    if args.max_epochs:
        # Stop when `max_epochs` has been reached
        trainer.add_hook(
            EPOCH_START, Hook(GEqThan(trainer.epochs, args.max_epochs), trainer.stop)
        )

    # Continue from the given checkpoint, if possible
    StateCheckpointLoader(experiment, device=device).load_by(
        os.path.join(args.train_path, "experiment.{}".format(args.checkpoint))
    )

    experiment.run()

    # Experiment finished. Save the model separately
    ModelCheckpointSaver(
        CheckpointSaver(os.path.join(args.train_path, "model.ckpt")), model
    ).save(suffix="last")
