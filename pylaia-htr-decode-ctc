#!/usr/bin/env python3
import argparse
import os

import torch
from pytorch_lightning.utilities.parsing import str_to_bool

import laia.data.transforms as transforms
from laia.common.arguments import add_argument, add_defaults, args
from laia.common.loader import choose_by
from laia.data import ImageDataLoader, ImageFromListDataset
from laia.decoders import CTCGreedyDecoder
from laia.feeders import ImageFeeder, ItemFeeder
from laia.utils import SymbolsTable


def compute_char_segmentation(batch_segmentation, img_sizes, input):
    return [
        [v, batch_segmentation[i], 0, [i + 1], img_sizes[0] - 1]
        for i, v in enumerate(input)
    ]


def compute_word_segmentation(input, space):
    out2, cad, ci = [], [], (0, 0)
    for l in input:
        if l[0] != space:
            cad += [l[0]]
        else:
            if cad:
                out2.append(["".join(cad), ci[0], ci[1], l[1], l[4]])
            cad = []
            ci = (l[3], l[2])
    if cad:
        out2.append(["".join(cad), ci[0], ci[1], l[3], l[4]])
    return out2


if __name__ == "__main__":
    add_defaults(
        "batch_size",
        "train_path",
        "model_filename",
        "color_mode",
        logging_level="WARNING",
    )
    add_argument(
        "syms",
        type=argparse.FileType("r"),
        help="Symbols table mapping from strings to integers",
    )
    add_argument(
        "img_dirs",
        type=str,
        nargs="*",
        help="Directory containing word images. Optional if img_list contains whole paths",
    )
    add_argument(
        "img_list",
        type=argparse.FileType("r"),
        help="File containing images to decode. Doesn't require the extension",
    )
    add_argument(
        "--print_img_ids",
        type=str_to_bool,
        nargs="?",
        const=True,
        default=True,
        help="Print output with the associated image id",
    )
    add_argument(
        "--separator",
        type=str,
        default=" ",
        help="Use this string as the separator between the ids and the output",
    )
    add_argument("--join_str", type=str, help="Join the output using this")
    add_argument(
        "--use_letters", action="store_true", help="Print the output with letters"
    )
    add_argument(
        "--convert_spaces", action="store_true", help="Whether or not to convert spaces"
    )
    add_argument(
        "--input_space",
        type=str,
        default="<space>",
        help="Input space symbol to replace",
    )
    add_argument(
        "--output_space", type=str, default="", help="Output space symbol",
    )
    add_argument(
        "--print_segmentation",
        type=str,
        default=None,
        choices=["char", "word"],
        help="Print output with the corresponding segmentation",
    )
    args = args()

    syms = SymbolsTable(args.syms)
    device = torch.device("cuda:{}".format(args.gpu - 1) if args.gpu else "cpu")

    checkpoint = choose_by(os.path.join(args.train_path, args.checkpoint))
    # TODO
    model = PLModel.load_from_checkpoint(checkpoint)

    model.eval()

    dataset = ImageFromListDataset(
        args.img_list,
        img_dirs=args.img_dirs,
        img_transform=transforms.vision.ToImageTensor(
            mode=args.color_mode, invert=True
        ),
    )
    dataset_loader = ImageDataLoader(
        dataset=dataset,
        image_channels=len(args.color_mode),
        batch_size=args.batch_size,
        num_workers=8,
    )
    batch_input_fn = ImageFeeder(device=device, parent_feeder=ItemFeeder("img"))

    decoder = CTCGreedyDecoder()
    for batch in dataset_loader:
        batch_input = batch_input_fn(batch)
        batch_output = model(batch_input)
        batch_decode = decoder(batch_output, segmentation=bool(args.print_segmentation))
        if args.print_segmentation == "char":
            img_sizes = batch_input.sizes.tolist()
            batch_segmentation = [
                [int(i * (y[1] - 1) / x[-1]) for i in x]
                for x, y in zip(decoder.segmentation, img_sizes)
            ]
        for i, (img_id, out) in enumerate(zip(batch["id"], batch_decode)):
            if args.use_letters or bool(args.print_segmentation):
                out = [str(syms[val]) for val in out]
            if args.print_segmentation == "char":
                out = compute_char_segmentation(
                    batch_segmentation[i], img_sizes[i], out
                )
            elif args.print_segmentation == "word":
                out = compute_word_segmentation(out, args.input_space)
            if not bool(args.print_segmentation):
                if args.convert_spaces:
                    out = [
                        args.output_space if sym == args.input_space else sym
                        for sym in out
                    ]
                if args.join_str is not None:
                    out = args.join_str.join(str(x) for x in out)
            print(
                "{}{}{}".format(img_id, args.separator, out)
                if args.print_img_ids
                else out
            )
