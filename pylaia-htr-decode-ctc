#!/usr/bin/env python3
import argparse
import os
from collections import OrderedDict

import pytorch_lightning as pl
import torch

import laia.common.logging as log
from laia import get_installed_versions
from laia.callbacks import Decode, ProgressBar
from laia.common.arguments import (
    add_argument,
    add_defaults,
    add_lightning_args,
    args,
    group_to_namespace,
)
from laia.common.loader import ModelLoader, choose_by
from laia.engine import DataModule
from laia.engine.feeders import Compose, ImageFeeder, ItemFeeder
from laia.engine.htr_evaluator_module import HTREvaluatorModule
from laia.utils import SymbolsTable


def main(args):
    log.info(f"Installed: {get_installed_versions()}")

    checkpoint_path = os.path.join(
        args.train_path, args.experiment_dirname, args.checkpoint
    )
    checkpoint = choose_by(checkpoint_path)
    if not checkpoint:
        log.error(f'Could not find the checkpoint="{checkpoint_path}"')
        exit(1)
    log.info(f'Using checkpoint="{checkpoint}')

    model = ModelLoader(args.train_path, filename=args.model_filename).load()
    if model is None:
        log.error('Could not find the model. Have you run "pylaia-htr-create-model"?')
        exit(1)
    state_dict = torch.load(checkpoint)["state_dict"]
    new_state_dict = OrderedDict()
    for k, v in state_dict.items():
        name = k[len("model.") :]
        new_state_dict[name] = v
    model.load_state_dict(new_state_dict)

    evaluator_module = HTREvaluatorModule(
        model,
        batch_input_fn=Compose([ItemFeeder("img"), ImageFeeder()]),
        batch_id_fn=ItemFeeder("id"),
        segmentation=bool(args.print_segmentation),
    )

    syms = SymbolsTable(args.syms)

    data_module = DataModule(args, syms=syms, stage="test")

    callbacks = [
        Decode(
            syms,
            use_letters=args.use_letters,
            segmentation=args.print_segmentation,
            input_space=args.input_space,
            output_space=args.output_space,
            convert_spaces=args.convert_spaces,
            join_str=args.join_str,
            separator=args.separator,
            print_img_ids=args.print_img_ids,
        ),
        ProgressBar(refresh_rate=args.lightning.progress_bar_refresh_rate),
    ]

    trainer = pl.Trainer(
        default_root_dir=args.train_path,
        callbacks=callbacks,
        **vars(args.lightning),
    )
    trainer.test(evaluator_module, datamodule=data_module, verbose=False)


if __name__ == "__main__":
    parser = add_defaults(
        "batch_size",
        "train_path",
        "model_filename",
        "experiment_dirname",
        "color_mode",
    )
    add_argument(
        "syms",
        type=argparse.FileType("r"),
        help="Symbols table mapping from strings to integers",
    )
    add_argument(
        "img_list",
        type=argparse.FileType("r"),
        help="File containing images to decode. Doesn't require the extension",
    )
    add_argument(
        "checkpoint",
        type=str,
        help="Name of the model checkpoint to use, can be a glob pattern",
    )
    add_argument(
        "img_dirs",
        type=str,
        nargs="*",
        help=(
            "Directory containing word images. "
            "Optional if img_list contains whole paths"
        ),
    )
    add_argument(
        "--print_img_ids",
        type=pl.utilities.parsing.str_to_bool,
        nargs="?",
        const=True,
        default=True,
        help="Print output with the associated image id",
    )
    add_argument(
        "--separator",
        type=str,
        default=" ",
        help="Use this string as the separator between the ids and the output",
    )
    add_argument(
        "--join_str", type=str, default=None, help="Join the output using this"
    )
    add_argument(
        "--use_letters", action="store_true", help="Print the output with letters"
    )
    add_argument(
        "--convert_spaces", action="store_true", help="Whether or not to convert spaces"
    )
    add_argument(
        "--input_space",
        type=str,
        default="<space>",
        help="Input space symbol to replace",
    )
    add_argument("--output_space", type=str, default="", help="Output space symbol")
    add_argument(
        "--print_segmentation",
        type=str,
        default=None,
        choices=["char", "word"],
        help="Print output with the corresponding segmentation",
    )

    # Add lightning default arguments to a group
    pl_group = parser.add_argument_group(title="pytorch-lightning arguments")
    pl_group = add_lightning_args(pl_group)

    args = args(parser=parser)

    # Move lightning default arguments to their own namespace
    args = group_to_namespace(args, pl_group, "lightning")
    # Delete some which will be set manually
    for a in ("default_root_dir",):
        delattr(args.lightning, a)

    main(args)
