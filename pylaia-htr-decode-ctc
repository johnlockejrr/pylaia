#!/usr/bin/env python3
import argparse
import os

import torch
from pytorch_lightning.utilities.parsing import str_to_bool

import laia.data.transforms as transforms
from laia.common.arguments import add_argument, add_defaults, args
from laia.common.loader import choose_by
from laia.data import ImageDataLoader, ImageFromListDataset
from laia.decoders import CTCGreedyDecoder
from laia.feeders import ImageFeeder, ItemFeeder
from laia.utils import SymbolsTable

if __name__ == "__main__":
    add_defaults(
        "batch_size",
        "train_path",
        "model_filename",
        "color_mode",
        logging_level="WARNING",
    )
    add_argument(
        "syms",
        type=argparse.FileType("r"),
        help="Symbols table mapping from strings to integers",
    )
    add_argument(
        "img_dirs",
        type=str,
        nargs="*",
        help="Directory containing word images. Optional if img_list contains whole paths",
    )
    add_argument(
        "img_list",
        type=argparse.FileType("r"),
        help="File containing images to decode. Doesn't require the extension",
    )
    add_argument(
        "--print_img_ids",
        type=str_to_bool,
        nargs="?",
        const=True,
        default=True,
        help="Print output with the associated image id",
    )
    add_argument(
        "--separator",
        type=str,
        default=" ",
        help="Use this string as the separator between the ids and the output",
    )
    add_argument("--join_str", type=str, help="Join the output using this")
    add_argument(
        "--use_letters", action="store_true", help="Print the output with letters"
    )
    add_argument(
        "--space", type=str, help="Replace <space> with this. Used with --use_letters"
    )
    args = args()

    syms = SymbolsTable(args.syms)
    device = torch.device("cuda:{}".format(args.gpu - 1) if args.gpu else "cpu")

    checkpoint = choose_by(os.path.join(args.train_path, args.checkpoint))
    # TODO
    model = PLModel.load_from_checkpoint(checkpoint)

    model.eval()

    dataset = ImageFromListDataset(
        args.img_list,
        img_dirs=args.img_dirs,
        img_transform=transforms.vision.ToImageTensor(
            mode=args.color_mode, invert=True
        ),
    )
    dataset_loader = ImageDataLoader(
        dataset=dataset,
        image_channels=len(args.color_mode),
        batch_size=args.batch_size,
        num_workers=8,
    )
    batch_input_fn = ImageFeeder(device=device, parent_feeder=ItemFeeder("img"))

    decoder = CTCGreedyDecoder()
    for batch in dataset_loader:
        batch_input = batch_input_fn(batch)
        batch_output = model(batch_input)
        batch_decode = decoder(batch_output)
        for img_id, out in zip(batch["id"], batch_decode):
            if args.use_letters:
                out = [str(syms[val]) for val in out]
                if args.space:
                    out = [args.space if sym == "<space>" else sym for sym in out]
            if args.join_str is not None:
                out = args.join_str.join(str(x) for x in out)
            print(
                "{}{}{}".format(img_id, args.separator, out)
                if args.print_img_ids
                else out
            )
