#!/usr/bin/env python
from __future__ import absolute_import

import argparse
import os
from typing import Any

import torch
import torch.nn.functional as functional

import laia.logging as log
from laia.data import ImageDataLoader, ImageFromListDataset
from laia.engine.feeders import ImageFeeder, ItemFeeder
from laia.losses.ctc_loss import transform_output
from laia.plugins.arguments import add_argument, args, add_defaults
from laia.plugins.loader import ModelLoader, ModelCheckpointLoader
from laia.utils import ImageToTensor


def _add_boundary_blank(cols):
    # type: (int) -> str
    matrix = "0 "
    matrix += " ".join(["-1e+30"] * (cols - 1))
    return matrix + "\n"


def output_matrix(
    img_id,  # type: str
    output,  # type: torch.Tensor
    output_size,  # type: int
    add_boundary_ctc_blank=False,  # type: bool
    digits=10,  # type: int
):
    # type: (...) -> str
    output = output.cpu()
    matrix = "{} [\n".format(img_id)
    boundary = _add_boundary_blank(output.size(1)) if add_boundary_ctc_blank else ""
    matrix += boundary
    matrix += (
        "\n".join(
            " ".join(
                "{:.{digits}}".format(float(output[row, col]), digits=digits)
                for col in range(output.size(1))
            )
            for row in range(output_size)
        )
        + "\n"
    )
    matrix += boundary
    matrix += "]\n"
    return matrix


def output_lattice(
    img_id,  # type: str
    output,  # type: torch.Tensor
    output_size,  # type: int
    digits=10,  # type: int
    **_  # type: **Any
):
    # type: (...) -> str
    output = output.cpu()
    matrix = "{}\n".format(img_id)
    matrix += (
        "\n".join(
            "{:d}\t{:d}\t{:d}\t0,{:.{digits}},{:d}".format(
                row, row + 1, col + 1, float(output[row, col]), col + 1, digits=digits
            )
            for row in range(output_size)
            for col in range(output.size(1))
        )
        + "\n"
    )
    matrix += "{:d}\t0,0,\n".format(output_size)
    return matrix


if __name__ == "__main__":
    add_defaults("batch_size", "gpu", "train_path", logging_level="WARNING")
    add_argument(
        "img_dirs", type=str, nargs="+", help="Directory containing word images"
    )
    add_argument(
        "img_list",
        type=argparse.FileType("r"),
        help="File or list containing images to decode",
    )
    add_argument(
        "--model_filename", type=str, default="model", help="File name of the model"
    )
    add_argument(
        "--model_checkpoint",
        type=str,
        default="model.ckpt.lowest-valid-cer*",
        help="Name of the model checkpoint to use, can be a glob pattern",
    )
    add_argument(
        "--output_transform",
        type=str,
        default=None,
        choices=["softmax", "log_softmax"],
        help="Apply this transformation at the end of the model. "
        'For instance, use "softmax" to get posterior probabilities as the '
        "output of the model",
    )
    add_argument(
        "--output_format",
        default="matrix",
        choices=["matrix", "lattice"],
        help='Format of the output file. Use "matrix" to get a '
        "Kaldi's archive of matrices (one for each sample), where each row is a "
        'timestep and each column represents a label; use "lattice" to get a '
        "Kaldi's archive of CompactLattices",
    )
    add_argument(
        "--add_boundary_ctc_blank",
        action="store_true",
        help="Boundary CTC blank symbol added to the start and end of the matrix",
    )
    add_argument(
        "--digits",
        type=int,
        default=10,
        help="Number of digits to be used for formatting",
    )
    args = args()

    model = ModelLoader(
        args.train_path, filename=args.model_filename, gpu=args.gpu
    ).load()
    if model is None:
        log.error('Could not find the model. Have you run "pylaia-htr-create-model"?')
        exit(1)
    model = model.cuda(args.gpu - 1) if args.gpu else model.cpu()
    ModelCheckpointLoader(model, gpu=args.gpu).load_by(
        os.path.join(args.train_path, args.model_checkpoint)
    )
    model.eval()

    dataset = ImageFromListDataset(
        args.img_list, img_dirs=args.img_dirs, img_transform=ImageToTensor()
    )
    dataset_loader = ImageDataLoader(
        dataset=dataset, image_channels=1, batch_size=args.batch_size, num_workers=8
    )
    batch_input_fn = ImageFeeder(device=args.gpu, parent_feeder=ItemFeeder("img"))

    output_fn = globals()["output_{}".format(args.output_format)]

    for batch in dataset_loader:
        batch_input = batch_input_fn(batch)
        batch_output = model(batch_input)
        batch_output, batch_sizes = transform_output(batch_output)
        batch_output = batch_output.permute(1, 0, 2)
        if args.output_transform:
            batch_output = getattr(functional, args.output_transform)(
                batch_output, dim=-1
            )
        for img_id, out, out_size in zip(batch["id"], batch_output, batch_sizes):
            matrix = output_fn(
                img_id,
                out,
                out_size,
                add_boundary_ctc_blank=args.add_boundary_ctc_blank,
                digits=args.digits,
            )
            print(matrix)
