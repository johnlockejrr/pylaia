#!/usr/bin/env python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse

import torch
import torch.nn as nn
from torch.autograd import Variable
from torch.utils.data import DataLoader

import laia
import laia.models.htr
from laia.distorter import ImageDistorter

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--batch_size', type=int, default=8,
                        help='Batch size')
    parser.add_argument('--learning_rate', type=float, default=0.0005,
                        help='Learning rate')
    parser.add_argument('--momentum', type=float, default=None,
                        help='Momentum')
    parser.add_argument('--max_updates', type=int, default=None,
                        help='Maximum number of training updates (iterations)')
    parser.add_argument('--gpu', type=int, default=1,
                        help='Use this GPU (starting from 1)')
    parser.add_argument('syms')
    parser.add_argument('tr_img_dir')
    parser.add_argument('tr_txt_table')
    parser.add_argument('va_txt_table')

    args = parser.parse_args()

    syms = laia.utils.SymbolsTable(args.syms)

    tr_ds = laia.data.TextImageFromTextTableDataset(
        args.tr_txt_table, args.tr_img_dir,
        img_transform=laia.utils.ImageToTensor(),
        txt_transform=laia.utils.TextToTensor(syms))
    tr_ds_loader = DataLoader(tr_ds, args.batch_size, num_workers=8,
                              collate_fn=laia.data.PaddingCollater({
                                  'img': [1, None, None]
                              }, sort_key=lambda x: -x['img'].size(2)),
                              shuffle=True)

    va_ds = laia.data.TextImageFromTextTableDataset(
        args.va_txt_table, args.tr_img_dir,
        img_transform=laia.utils.ImageToTensor(),
        txt_transform=laia.utils.TextToTensor(syms))
    va_ds_loader = DataLoader(va_ds, args.batch_size, num_workers=8,
                              collate_fn=laia.data.PaddingCollater({
                                  'img': [1, None, None]
                              }, sort_key=lambda x: -x['img'].size(2)))

    """
    model = laia.models.htr.VggRnnFixedHeight(120, 1, 84, [16, 16, 32, 32],
                                   [3] * 4,
                                   [1] * 4,
                                   [nn.LeakyReLU] * 4,
                                   [2, 2, 2, 0],
                                   [0.0] * 4,
                                   [False] * 4,
                                   256, 3, 0.5, 0.5)
    """

    # SOTA model for IAM/Rimes
    model = laia.models.htr.VggRnnFixedHeight(
        128, 1, 80, [16, 32, 48, 64, 80],
        [3] * 5,
        [1] * 5,
        [nn.LeakyReLU] * 5,
        [2, 2, 2, 0, 0],
        [0.0, 0.0, 0.2, 0.2, 0.2],
        [True] * 5,
        256, 5, 0.5, 0.5)

    if args.gpu > 0:
        model = model.cuda(args.gpu - 1)
    else:
        model = model.cpu()

    parameters = model.parameters()
    optimizer = torch.optim.RMSprop(parameters, lr=args.learning_rate,
                                    momentum=args.momentum)

    distorter = ImageDistorter()


    def batch_input_fn(batch):
        assert (isinstance(batch['img'], laia.data.PaddedTensor) or
                torch.is_tensor(batch['img']))
        if isinstance(batch['img'], laia.data.PaddedTensor):
            x = batch['img'].data
            xs = batch['img'].sizes[:, 1:].contiguous()
            if args.gpu > 0:
                x, xs = x.cuda(args.gpu - 1), xs.cuda(args.gpu - 1)
            else:
                x, xs = x.cpu(), xs.cpu()
            return laia.data.PaddedTensor(data=Variable(x), sizes=xs)
        else:
            if args.gpu > 0:
                x = batch['img'].cuda(args.gpu - 1)
            else:
                x = batch['img'].cpu()
            return Variable(x)


    def batch_target_fn(batch):
        return batch['txt']


    def distort_input_fn(batch):
        x = batch_input_fn(batch)
        if isinstance(x, laia.data.PaddedTensor):
            x, xs = x.data, x.sizes
            x = x.data if isinstance(x, Variable) else x
            xs = xs.data if isinstance(xs, Variable) else xs
            return laia.data.PaddedTensor(data=Variable(distorter(x)), sizes=xs)
        else:
            x = x.data if isinstance(x, Variable) else x
            return Variable(x)


    def report_epoch_info(**kwargs):
        # Average training loss since the start of training
        tr_run_loss = train_running_loss_meter.value[0]
        # Average training loss in the last EPOCH
        tr_loss = train_loss_meter.value[0]
        # Average training CER in the last EPOCH
        tr_cer = train_cer_meter.value * 100
        # Average validation CER in the last EPOCH
        va_cer = valid_cer_meter.value * 100
        print(('Epoch %4d, '
               'TR Running Avg. Loss = %.3e, '
               'TR Loss = %.3e, '
               'TR CER = %3.2f%%, '
               'TR Elapsed Time = %.2fs, '
               'VA CER = %3.2f%%, '
               'VA Elapsed Time = %.2fs') % (
                  kwargs['epoch'],
                  tr_run_loss,
                  tr_loss,
                  tr_cer,
                  train_timer.value,
                  va_cer,
                  valid_timer.value))


    ctc = laia.losses.CTCLoss()
    trainer = laia.engine.Trainer(model=model,
                                  criterion=ctc,
                                  optimizer=optimizer,
                                  dataset=tr_ds_loader,
                                  batch_input_fn=distort_input_fn,
                                  batch_target_fn=batch_target_fn)

    evaluator = laia.engine.Evaluator(model=model,
                                      dataset=va_ds_loader,
                                      batch_input_fn=batch_input_fn,
                                      batch_target_fn=batch_target_fn)

    engine_wrapper = laia.engine.HtrEngineWrapper(trainer, evaluator)
    engine_wrapper.run()
