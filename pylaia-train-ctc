#!/usr/bin/env python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import collections


import laia
import laia.models.htr

import numpy as np
import torch
import torch.nn as nn

from collections import OrderedDict

from laia.distorter import ImageDistorter

from torch.autograd import Variable
from torch.utils.data import DataLoader
from laia.utils import image_collage

from PIL import ImageOps

class TextToTensor(object):
    def __init__(self, sym2int):
        assert isinstance(sym2int, dict)
        self._sym2int = sym2int

    def __call__(self, x):
        x = [self._sym2int[c] for c in x]
        return x

class ImageToTensor(object):
    def __init__(self, invert=True, mode='L'):
        assert mode in ('L', 'RGB', 'RGBA')
        self._invert = invert
        self._mode = mode

    def __call__(self, x):
        x = x.convert(self._mode)
        if self._invert:
            x = ImageOps.invert(x)
        x = np.asarray(x, dtype=np.float32)
        if len(x.shape) != 3:
            x = np.expand_dims(x, axis=-1)
        x = np.transpose(x, (2, 0, 1))
        return torch.from_numpy(x / 255.0)

def LoadSymbolsTable(f):
    if isinstance(f, (str, unicode)):
        f = open(f, 'r')
    sym2int, int2sym = OrderedDict(), OrderedDict()
    for n, line in enumerate(f, 1):
        line = line.split()
        s, v = line[0], int(line[1])
        sym2int[s] = v
        int2sym[v] = s
    f.close()
    assert len(sym2int) == len(int2sym), (
        'Repeated symbols or IDs in symbols table "%s"' % f.name)
    return sym2int, int2sym






if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--batch_size', type=int, default=8,
                        help='Batch size')
    parser.add_argument('--learning_rate', type=float, default=0.0005,
                        help='Learning rate')
    parser.add_argument('--momentum', type=float, default=None,
                        help='Momentum')
    parser.add_argument('--max_updates', type=int, default=None,
                        help='Maximum number of training updates (iterations)')
    parser.add_argument('--gpu', type=int, default=1,
                        help='Use this GPU (starting from 1)')
    parser.add_argument('syms')
    parser.add_argument('tr_img_dir')
    parser.add_argument('tr_txt_table')
    parser.add_argument('va_txt_table')

    args = parser.parse_args()

    sym2int, int2sym = LoadSymbolsTable(args.syms)

    tr_ds = laia.data.TextImageFromTextTableDataset(
        args.tr_txt_table, args.tr_img_dir,
        img_transform=ImageToTensor(),
        txt_transform=TextToTensor(sym2int))
    tr_ds_loader = DataLoader(tr_ds, args.batch_size, num_workers=8,
                              collate_fn=laia.data.PaddingCollater({
                                  'img': [1, None, None]
                              }, sort_key=lambda x: -x['img'].size(2)),
                              shuffle=True)

    va_ds = laia.data.TextImageFromTextTableDataset(
        args.va_txt_table, args.tr_img_dir,
        img_transform=ImageToTensor(),
        txt_transform=TextToTensor(sym2int))
    va_ds_loader = DataLoader(va_ds, args.batch_size, num_workers=8,
                              collate_fn=laia.data.PaddingCollater({
                                  'img': [1, None, None]
                              }, sort_key=lambda x: -x['img'].size(2)))


    """
    model = laia.models.htr.VggRnnFixedHeight(120, 1, 84, [16, 16, 32, 32],
                                   [3] * 4,
                                   [1] * 4,
                                   [nn.LeakyReLU] * 4,
                                   [2, 2, 2, 0],
                                   [0.0] * 4,
                                   [False] * 4,
                                   256, 3, 0.5, 0.5)
    """

    # SOTA model for IAM/Rimes
    model = laia.models.htr.VggRnnFixedHeight(
        128, 1, 80, [16, 32, 48, 64, 80],
        [3] * 5,
        [1] * 5,
        [nn.LeakyReLU] * 5,
        [2, 2, 2, 0, 0],
        [0.0, 0.0, 0.2, 0.2, 0.2],
        [True] * 5,
        256, 5, 0.5, 0.5)

    if args.gpu > 0:
        model = model.cuda(args.gpu - 1)
    else:
        model = model.cpu()

    ctc_decoder = laia.decoders.CTCDecoder()
    seq_err_meter = laia.meters.SequenceErrorMeter()
    epoch_timer = laia.meters.TimeMeter()

    parameters = model.parameters()
    optimizer = torch.optim.RMSprop(parameters, lr=args.learning_rate,
                                    momentum=args.momentum)

    distorter = ImageDistorter()

    def batch_input_fn(batch):
        assert (isinstance(batch['img'], laia.data.PaddedTensor) or
                torch.is_tensor(batch['img']))
        if isinstance(batch['img'], laia.data.PaddedTensor):
            x = batch['img'].data
            xs = batch['img'].sizes[:, 1:].contiguous()
            if args.gpu > 0:
                x, xs = x.cuda(args.gpu - 1), xs.cuda(args.gpu - 1)
            else:
                x, xs = x.cpu(), xs.cpu()
            return laia.data.PaddedTensor(data=Variable(x), sizes=xs)
        else:
            if args.gpu > 0:
                x = batch['img'].cuda(args.gpu - 1)
            else:
                x = batch['img'].cpu()
            return Variable(x)

    def batch_target_fn(batch):
        return batch['txt']

    def distort_input_fn(batch):
        x = batch_input_fn(batch)
        if isinstance(x, laia.data.PaddedTensor):
            x, xs = x.data, x.sizes
            x = x.data if isinstance(x, Variable) else x
            xs = xs.data if isinstance(xs, Variable) else xs
            return laia.data.PaddedTensor(data=Variable(distorter(x)), sizes=xs)
        else:
            x = x.data if isinstance(x, Variable) else x
            return Variable(x)

    def on_start_epoch(**kwargs):
        epoch_timer.reset()

    def on_start_batch(**kwargs):
        seq_err_meter.reset()

    def on_end_batch(**kwargs):
        batch_decode = ctc_decoder(kwargs['batch_output'])
        seq_err_meter.add(kwargs['batch_target'], batch_decode)

    def on_end_epoch(**kwargs):
        print('Epoch %05d, train error rate = %3.2f%%, elapsed time = %.2fs' % (
            kwargs['epoch'], seq_err_meter.value * 100, epoch_timer.value))


    ctc = laia.losses.CTCLoss()
    trainer = laia.engine.Trainer(model=model,
                                  criterion=ctc,
                                  optimizer=optimizer,
                                  dataset=tr_ds_loader,
                                  batch_input_fn=distort_input_fn,
                                  batch_target_fn=batch_target_fn)
    trainer.register_hook('on_start_epoch', on_start_epoch)
    trainer.register_hook('on_start_batch', on_start_batch)
    trainer.register_hook('on_end_batch', on_end_batch)
    trainer.register_hook('on_end_epoch', on_end_epoch)

    evaluator = laia.engine.Evaluator(model=model,
                                      dataset=va_ds_loader,
                                      batch_input_fn=batch_input_fn,
                                      batch_target_fn=batch_target_fn)
    evaluator.register_hook('on_start_batch', on_start_batch)
    evaluator.register_hook('on_end_batch', on_end_batch)

    def evaluate_valid_end_epoch(**kwargs):
        evaluator.run()
        print('Epoch %05d, valid error rate = %3.2f%%' % (
            kwargs['epoch'], seq_err_meter.value * 100))

    trainer.register_hook('on_end_epoch', evaluate_valid_end_epoch)

    trainer.run()
