#!/usr/bin/env python
from __future__ import absolute_import
from __future__ import division

import torch
import torch.nn as nn
from torch.utils.data import DataLoader

import laia.models.htr
from laia.engine.feeders import ImageFeeder, ItemFeeder
from laia.utils.arguments import add_argument, args, add_defaults

if __name__ == '__main__':
    add_defaults('batch_size', 'learning_rate', 'momentum', 'gpu')
    add_argument('--max_updates', type=int, default=None,
                 help='Maximum number of training updates (iterations)')
    add_argument('syms')
    add_argument('tr_img_dir')
    add_argument('tr_txt_table')
    add_argument('va_txt_table')
    args = args()
    laia.utils.logging.config_from_args(args)

    syms = laia.utils.SymbolsTable(args.syms)

    tr_ds = laia.data.TextImageFromTextTableDataset(
        args.tr_txt_table, args.tr_img_dir,
        img_transform=laia.utils.ImageToTensor(),
        txt_transform=laia.utils.TextToTensor(syms))
    tr_ds_loader = DataLoader(tr_ds, args.batch_size, num_workers=8,
                              collate_fn=laia.data.PaddingCollater({
                                  'img': [1, None, None]
                              }, sort_key=lambda x: -x['img'].size(2)),
                              shuffle=True)

    va_ds = laia.data.TextImageFromTextTableDataset(
        args.va_txt_table, args.tr_img_dir,
        img_transform=laia.utils.ImageToTensor(),
        txt_transform=laia.utils.TextToTensor(syms))
    va_ds_loader = DataLoader(va_ds, args.batch_size, num_workers=8,
                              collate_fn=laia.data.PaddingCollater({
                                  'img': [1, None, None]
                              }, sort_key=lambda x: -x['img'].size(2)))

    """
    model = laia.models.htr.VggRnnFixedHeight(120, 1, 84, [16, 16, 32, 32],
                                   [3] * 4,
                                   [1] * 4,
                                   [nn.LeakyReLU] * 4,
                                   [2, 2, 2, 0],
                                   [0.0] * 4,
                                   [False] * 4,
                                   256, 3, 0.5, 0.5)
    """

    # SOTA model for IAM/Rimes
    model = laia.models.htr.VggRnnFixedHeight(
        128, 1, 80, [16, 32, 48, 64, 80],
        [3] * 5,
        [1] * 5,
        [nn.LeakyReLU] * 5,
        [2, 2, 2, 0, 0],
        [0.0, 0.0, 0.2, 0.2, 0.2],
        [True] * 5,
        256, 5, 0.5, 0.5)

    if args.gpu > 0:
        model = model.cuda(args.gpu - 1)
    else:
        model = model.cpu()

    parameters = model.parameters()
    optimizer = torch.optim.RMSprop(parameters,
                                    lr=args.learning_rate,
                                    momentum=args.momentum)

    trainer = laia.engine.Trainer(
        model=model,
        # This is set automatically by HtrEngineWrapper
        criterion=None,
        optimizer=optimizer,
        data_loader=tr_ds_loader,
        batch_input_fn=ImageFeeder(device=args.gpu,
                                   parent_feeder=ItemFeeder('img')),
        batch_target_fn=ItemFeeder('txt'))

    evaluator = laia.engine.Evaluator(
        model=model,
        data_loader=va_ds_loader,
        batch_input_fn=ImageFeeder(device=args.gpu,
                                   parent_feeder=ItemFeeder('img')),
        batch_target_fn=ItemFeeder('txt'))

    engine_wrapper = laia.engine.HtrEngineWrapper(trainer, evaluator)
    engine_wrapper.run()
