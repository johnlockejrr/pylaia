#!/usr/bin/env python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import collections


import laia
import laia.models.htr

import numpy as np
import torch
import torch.nn as nn

from collections import OrderedDict

from laia.distorter import ImageDistorter

from torch.autograd import Variable
from torch.utils.data import DataLoader
from laia.utils import image_collage

from PIL import ImageOps

class TextToTensor(object):
    def __init__(self, sym2int):
        assert isinstance(sym2int, dict)
        self._sym2int = sym2int

    def __call__(self, x):
        x = [self._sym2int[c] for c in x]
        return x

class ImageToTensor(object):
    def __init__(self, invert=True, mode='L'):
        assert mode in ('L', 'RGB', 'RGBA')
        self._invert = invert
        self._mode = mode

    def __call__(self, x):
        x = x.convert(self._mode)
        if self._invert:
            x = ImageOps.invert(x)
        x = np.asarray(x, dtype=np.float32)
        if len(x.shape) != 3:
            x = np.expand_dims(x, axis=-1)
        x = np.transpose(x, (2, 0, 1))
        return torch.from_numpy(x / 255.0)

def LoadSymbolsTable(f):
    if isinstance(f, (str, unicode)):
        f = open(f, 'r')
    sym2int, int2sym = OrderedDict(), OrderedDict()
    for n, line in enumerate(f, 1):
        line = line.split()
        s, v = line[0], int(line[1])
        sym2int[s] = v
        int2sym[v] = s
    f.close()
    assert len(sym2int) == len(int2sym), (
        'Repeated symbols or IDs in symbols table "%s"' % f.name)
    return sym2int, int2sym






if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--batch_size', type=int, default=8,
                        help='Batch size')
    parser.add_argument('--learning_rate', type=float, default=0.0005,
                        help='Learning rate')
    parser.add_argument('--momentum', type=float, default=None,
                        help='Momentum')
    parser.add_argument('--max_updates', type=int, default=None,
                        help='Maximum number of training updates (iterations)')
    parser.add_argument('--gpu', type=int, default=1,
                        help='Use this GPU (starting from 1)')
    parser.add_argument('syms')
    parser.add_argument('tr_img_dir')
    parser.add_argument('tr_txt_table')
    parser.add_argument('va_txt_table')

    args = parser.parse_args()

    sym2int, int2sym = LoadSymbolsTable(args.syms)

    tr_ds = laia.data.TextImageFromTextTableDataset(
        args.tr_txt_table, args.tr_img_dir,
        img_transform=ImageToTensor(),
        txt_transform=TextToTensor(sym2int))
    tr_ds_loader = DataLoader(tr_ds, args.batch_size, num_workers=8,
                              collate_fn=laia.data.PaddingCollater({
                                  'img': [1, None, None]
                              }, sort_key=lambda x: -x['img'].size(2)),
                              shuffle=True)

    va_ds = laia.data.TextImageFromTextTableDataset(
        args.va_txt_table, args.tr_img_dir,
        img_transform=ImageToTensor(),
        txt_transform=TextToTensor(sym2int))
    va_ds_loader = DataLoader(va_ds, args.batch_size, num_workers=8,
                              collate_fn=laia.data.PaddingCollater({
                                  'img': [1, None, None]
                              }, sort_key=lambda x: -x['img'].size(2)))


    """
    model = laia.models.htr.VggRnnFixedHeight(120, 1, 84, [16, 16, 32, 32],
                                   [3] * 4,
                                   [1] * 4,
                                   [nn.LeakyReLU] * 4,
                                   [2, 2, 2, 0],
                                   [0.0] * 4,
                                   [False] * 4,
                                   256, 3, 0.5, 0.5)
    """

    # SOTA model for IAM/Rimes
    model = laia.models.htr.VggRnnFixedHeight(
        128, 1, 80, [16, 32, 48, 64, 80],
        [3] * 5,
        [1] * 5,
        [nn.LeakyReLU] * 5,
        [2, 2, 2, 0, 0],
        [0.0, 0.0, 0.2, 0.2, 0.2],
        [True] * 5,
        256, 5, 0.5, 0.5)

    if args.gpu > 0:
        model = model.cuda(args.gpu - 1)
    else:
        model = model.cpu()

    ctc_decoder = laia.decoders.CTCDecoder()
    train_timer = laia.meters.TimeMeter()
    valid_timer = laia.meters.TimeMeter()
    train_running_loss_meter = laia.meters.RunningAverageMeter()
    train_loss_meter = laia.meters.RunningAverageMeter()
    valid_loss_meter = laia.meters.RunningAverageMeter()
    train_cer_meter  = laia.meters.SequenceErrorMeter()
    valid_cer_meter  = laia.meters.SequenceErrorMeter()


    parameters = model.parameters()
    optimizer = torch.optim.RMSprop(parameters, lr=args.learning_rate,
                                    momentum=args.momentum)

    distorter = ImageDistorter()

    def batch_input_fn(batch):
        assert (isinstance(batch['img'], laia.data.PaddedTensor) or
                torch.is_tensor(batch['img']))
        if isinstance(batch['img'], laia.data.PaddedTensor):
            x = batch['img'].data
            xs = batch['img'].sizes[:, 1:].contiguous()
            if args.gpu > 0:
                x, xs = x.cuda(args.gpu - 1), xs.cuda(args.gpu - 1)
            else:
                x, xs = x.cpu(), xs.cpu()
            return laia.data.PaddedTensor(data=Variable(x), sizes=xs)
        else:
            if args.gpu > 0:
                x = batch['img'].cuda(args.gpu - 1)
            else:
                x = batch['img'].cpu()
            return Variable(x)

    def batch_target_fn(batch):
        return batch['txt']

    def distort_input_fn(batch):
        x = batch_input_fn(batch)
        if isinstance(x, laia.data.PaddedTensor):
            x, xs = x.data, x.sizes
            x = x.data if isinstance(x, Variable) else x
            xs = xs.data if isinstance(xs, Variable) else xs
            return laia.data.PaddedTensor(data=Variable(distorter(x)), sizes=xs)
        else:
            x = x.data if isinstance(x, Variable) else x
            return Variable(x)

    def train_reset_meters(**kwargs):
        train_timer.reset()
        train_loss_meter.reset()
        train_cer_meter.reset()

    def valid_reset_meters(**kwargs):
        valid_timer.reset()
        valid_loss_meter.reset()
        valid_cer_meter.reset()

    def train_accumulate_loss(**kwargs):
        train_loss_meter.add(kwargs['batch_loss'])
        train_running_loss_meter.add(kwargs['batch_loss'])

    def train_compute_cer(**kwargs):
        batch_decode = ctc_decoder(kwargs['batch_output'])
        train_cer_meter.add(kwargs['batch_target'], batch_decode)

    def valid_compute_cer(**kwargs):
        batch_decode = ctc_decoder(kwargs['batch_output'])
        valid_cer_meter.add(kwargs['batch_target'], batch_decode)

    def report_epoch_info(**kwargs):
        # Average training loss since the start of training
        tr_run_loss = train_running_loss_meter.value[0]
        # Average training loss in the last EPOCH
        tr_loss = train_loss_meter.value[0]
        # Average training CER in the last EPOCH
        tr_cer = train_cer_meter.value * 100
        # Average validation CER in the last EPOCH
        va_cer = valid_cer_meter.value * 100
        print(('Epoch %4d, '
               'TR Running Avg. Loss = %.3e, '
               'TR Loss = %.3e, '
               'TR CER = %3.2f%%, '
               'TR Elapsed Time = %.2fs, '
               'VA CER = %3.2f%%, '
               'VA Elapsed Time = %.2fs') % (
                   kwargs['epoch'],
                   tr_run_loss,
                   tr_loss,
                   tr_cer,
                   train_timer.value,
                   va_cer,
                   valid_timer.value))


    evaluator = laia.engine.Evaluator(model=model,
                                      dataset=va_ds_loader,
                                      batch_input_fn=batch_input_fn,
                                      batch_target_fn=batch_target_fn)
    evaluator.add_hook('on_start_epoch', valid_reset_meters)
    evaluator.add_hook('on_end_batch', valid_compute_cer)


    ctc = laia.losses.CTCLoss()
    trainer = laia.engine.Trainer(model=model,
                                  criterion=ctc,
                                  optimizer=optimizer,
                                  dataset=tr_ds_loader,
                                  batch_input_fn=distort_input_fn,
                                  batch_target_fn=batch_target_fn)
    trainer.add_hook('on_start_epoch', train_reset_meters)

    trainer.add_hook('on_end_batch', train_accumulate_loss)
    trainer.add_hook('on_end_batch', train_compute_cer)

    # The evaluator should run BEFORE report_epoch_info()
    trainer.add_evaluator(evaluator)
    trainer.add_hook('on_end_epoch', report_epoch_info)



    trainer.run()
