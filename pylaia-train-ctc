#!/usr/bin/env python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import collections
import editdistance
import itertools
import laia.data
import laia.models.htr
import numpy as np
import torch

from collections import OrderedDict
from operator import mul
from torch.autograd import Variable
from torch.utils.data import DataLoader
import torch.nn as nn
from torch.nn.utils.rnn import PackedSequence, pad_packed_sequence, pack_padded_sequence
from warpctc_pytorch import CTCLoss as _CTCLoss


class TextToTensor(object):
    def __init__(self, sym2int):
        assert isinstance(sym2int, dict)
        self._sym2int = sym2int

    def __call__(self, x):
        x = [self._sym2int[c] for c in x]
        return x

class ImageToTensor(object):
    def __init__(self, invert=False, mode='F'):
        assert mode in ('F', 'L', 'RGB', 'RGBA')
        self._invert = invert
        self._mode = mode

    def __call__(self, x):
        x = x.convert(self._mode)
        if self._invert:
            x = x.invert()
        x = np.asarray(x, dtype=np.float32)
        if len(x.shape) != 3:
            x = np.expand_dims(x, axis=-1)
        x = np.transpose(x, (2, 0, 1))
        return torch.from_numpy(x / 255.0)

def LoadSymbolsTable(f):
    if isinstance(f, (str, unicode)):
        f = open(f, 'r')
    sym2int, int2sym = OrderedDict(), OrderedDict()
    for n, line in enumerate(f, 1):
        line = line.split()
        s, v = line[0], int(line[1])
        sym2int[s] = v
        int2sym[v] = s
    f.close()
    assert len(sym2int) == len(int2sym), (
        'Repeated symbols or IDs in symbols table "%s"' % f.name)
    return sym2int, int2sym

def GreedyDecoder(y, ys):
    # Shape y: T x N x L
    _, idx = y.max(dim=2)
    idx = idx.t().tolist()
    y = [idx_n[:int(ys[n])] for n, idx_n in enumerate(idx)]
    y = [reduce(lambda z, x: z if z[-1] == x else z + [x], y_n[1:], [y_n[0]])
         for y_n in y]
    y = [filter(lambda x: x != 0, y_n) for y_n in y]
    return y


def ComputeBatchErrorRate(batch_txt_ref, batch_txt_hyp):
    nerr, tlen = 0, 0
    for tr, th in zip(batch_txt_ref, batch_txt_hyp):
        nerr += editdistance.eval(tr, th)
        tlen += len(tr)
    return float(nerr) / float(tlen)


class CTCLoss(object):
    def __init__(self):
        self._ctc = _CTCLoss()

    def __call__(self, output, target):
        output = output.data if isinstance(output, Variable) else output
        x, xs = pad_packed_sequence(output)
        y, ys = target
        loss = self._ctc(x, y, xs, ys)
        loss = (loss / xs.type(torch.FloatTensor)).mean()
        return loss



if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--batch_size', type=int, default=8,
                        help='Batch size')
    parser.add_argument('--learning_rate', type=float, default=0.0005,
                        help='Learning rate')
    parser.add_argument('--momentum', type=float, default=None,
                        help='Momentum')
    parser.add_argument('--max_updates', type=int, default=None,
                        help='Maximum number of training updates (iterations)')
    parser.add_argument('--gpu', type=int, default=1,
                        help='Use this GPU (starting from 1)')
    parser.add_argument('syms')
    parser.add_argument('tr_img_dir')
    parser.add_argument('tr_txt_table')
    parser.add_argument('va_txt_table')

    args = parser.parse_args()

    sym2int, int2sym = LoadSymbolsTable(args.syms)

    tr_ds = laia.data.TextImageFromTextTableDataset(
        args.tr_txt_table, args.tr_img_dir,
        img_transform=ImageToTensor(),
        txt_transform=TextToTensor(sym2int))
    tr_ds_loader = DataLoader(tr_ds, args.batch_size, num_workers=8,
                              collate_fn=laia.data.PaddingCollater({
                                  'img': [1, None, None]
                              }, sort_key=lambda x: -x['img'].size(2)),
                              shuffle=True)

    va_ds = laia.data.TextImageFromTextTableDataset(
        args.va_txt_table, args.tr_img_dir,
        img_transform=ImageToTensor(),
        txt_transform=TextToTensor(sym2int))
    va_ds_loader = DataLoader(va_ds, args.batch_size, num_workers=8,
                              collate_fn=laia.data.PaddingCollater({
                                  'img': [1, None, None]
                              }, sort_key=lambda x: -x['img'].size(2)))


    model = laia.models.htr.VggRnnFixedHeight(120, 1, 84, [16, 16, 32, 32],
                                   [3] * 4,
                                   [1] * 4,
                                   [nn.LeakyReLU] * 4,
                                   [2, 2, 2, 0],
                                   [0.0] * 4,
                                   [False] * 4,
                                   256, 3, 0.5, 0.5)

    if args.gpu:
        model.cuda(args.gpu - 1)


    parameters = model.parameters()
    optimizer = torch.optim.RMSprop(parameters, lr=args.learning_rate,
                                    momentum=args.momentum)

    ctc = CTCLoss()
    trainer = laia.Trainer(model=model, criterion=ctc, optimizer=optimizer, dataset=tr_ds_loader)


    """
    it, epoch = 0, 0
    training_done = False
    while not training_done:
        epoch = epoch + 1
        model.train()
        for batch in tr_ds_loader:
            it = it + 1
            if args.max_updates and it > args.max_updates:
                training_done = True
                break

            x = Variable(batch['img'].data)
            xs = batch['img'].sizes[:,1:]
            if args.gpu:
                x = x.cuda(args.gpu - 1)
                #xs = xs.cuda(args.gpu - 1)

            y = model(laia.data.PaddedTensor(x, xs))
            y, ys = pad_packed_sequence(y)

            targets = list(itertools.chain.from_iterable(batch['txt']))
            targets_size = map(lambda x: len(x), batch['txt'])

            targets = Variable(torch.IntTensor(targets), requires_grad=False)
            targets_size = Variable(torch.IntTensor(targets_size),
                                    requires_grad=False)
            ys = Variable(torch.IntTensor(ys), requires_grad=False)

            loss = ctc(y, targets, ys, targets_size)
            loss = (loss / ys.type(torch.FloatTensor)).mean()

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        model.eval()
        va_ref = []
        va_hyp = []
        for batch in va_ds_loader:
            x = Variable(batch['img'].data)
            xs = batch['img'].sizes[:,1:]
            if args.gpu:
                x = x.cuda(args.gpu - 1)

            y = model(laia.data.PaddedTensor(x, xs))
            y, ys = pad_packed_sequence(y)
            va_ref.extend(batch['txt'])
            va_hyp.extend(GreedyDecoder(y.data, ys))
        va_cer = ComputeBatchErrorRate(va_ref, va_hyp)


        tr_ref = []
        tr_hyp = []
        for batch in tr_ds_loader:
            x = Variable(batch['img'].data)
            xs = batch['img'].sizes[:,1:]
            if args.gpu:
                x = x.cuda(args.gpu - 1)

            y = model(laia.data.PaddedTensor(x, xs))
            y, ys = pad_packed_sequence(y)
            tr_ref.extend(batch['txt'])
            tr_hyp.extend(GreedyDecoder(y.data, ys))
        tr_cer = ComputeBatchErrorRate(tr_ref, tr_hyp)

        print('EPOCH %d %6.2f %6.2f' % (epoch, tr_cer * 100, va_cer * 100))
    """
